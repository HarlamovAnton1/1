{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Привет, меня зовут Артем Хуршудов. Сегодня я проверю твой проект.\n",
    "<br> Дальнейшее общение будет происходить на \"ты\" если это не вызывает никаких проблем.\n",
    "<br> Желательно реагировать на каждый мой комментарий ('исправил', 'не понятно как исправить ошибку', ...)\n",
    "<br> Пожалуйста, не удаляй комментарии ревьюера, так как они повышают качество повторного ревью.\n",
    "\n",
    "Комментарии будут в <font color='green'>зеленой</font>, <font color='blue'>синей</font> или <font color='red'>красной</font> рамках:\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Если все сделано отлично\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Если можно немного улучшить\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Если требуются исправления. Работа не может быть принята с красными комментариями.\n",
    "</div>\n",
    "\n",
    "### <font color='orange'>Общее впечатление</font>\n",
    "* Большое спасибо за проделанную работу. Видно, что приложено много усилий.\n",
    "* Радует, что ноутбук хорошо структурирован. Приятно проверять такие работы.\n",
    "* Отлично, что стоп-слова были исключены при векторизации!\n",
    "* К сожалению, в работе допущено несколько ошибок. Надеюсь, исправления не займут много времени.\n",
    "* Также я оставил несколько советов. Обрати на них внимание.\n",
    "* Жду новую версию проекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Артем, привет! На \"ты\" очень даже отлично =) \n",
    "Спасибо за такую оперативную проверку, комментарии и советы) Постаралась все учесть и подправить. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* После исправлений работа значительно улучшилась.\n",
    "* Радует, что советы также были учтены.\n",
    "* К сожалению в последнем шаге допущена ошибка. Почему модель обучается и тестируется на одной и той же выборке? Разве такое имеет смысл?\n",
    "* Отправляй новую версию как только будут готовы изменения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Артем, ты прав) ошибку исправила."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='orange'>Общее впечатление (ревью 2)</font>\n",
    "* Вот теперь все корректно, молодец!\n",
    "* Работа получилась отличной, тебе удалось добиться достаточно хорошего качества. Поздравляю!\n",
    "* Проект зачтен, удачи в дальнейшем обучении!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "### Инструкция по выполнению проекта\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "import string\n",
    "from sklearn.svm import LinearSVC\n",
    "from nltk import word_tokenize, pos_tag\n",
    "import re\n",
    "from itertools import product\n",
    "import warnings\n",
    "from joblib import dump, load\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook, notebook\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "rnd_state = 12345\n",
    "data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Желательно чтобы все импорты были собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>\n",
    "\n",
    "- готово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ознакомимся с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>146790</td>\n",
       "      <td>Ahh shut the fuck up you douchebag sand nigger...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2941</td>\n",
       "      <td>\"\\n\\nREPLY: There is no such thing as Texas Co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115087</td>\n",
       "      <td>Reply\\nHey, you could at least mention Jasenov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48830</td>\n",
       "      <td>Thats fine, there is no deadline )   chi?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136034</td>\n",
       "      <td>\"\\n\\nDYK nomination of Mustarabim\\n Hello! You...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121992</td>\n",
       "      <td>\"\\n\\nSockpuppetry case\\n \\nYou have been accus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37282</td>\n",
       "      <td>Judging by what I've just read in an article, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64488</td>\n",
       "      <td>Todd and Copper\\nIn the first film they were l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16992</td>\n",
       "      <td>\"\\n\\n \\nYou have been blocked from editing for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138230</td>\n",
       "      <td>| decline=Can't find evidence of block either ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "146790  Ahh shut the fuck up you douchebag sand nigger...      1\n",
       "2941    \"\\n\\nREPLY: There is no such thing as Texas Co...      0\n",
       "115087  Reply\\nHey, you could at least mention Jasenov...      0\n",
       "48830           Thats fine, there is no deadline )   chi?      0\n",
       "136034  \"\\n\\nDYK nomination of Mustarabim\\n Hello! You...      0\n",
       "121992  \"\\n\\nSockpuppetry case\\n \\nYou have been accus...      0\n",
       "37282   Judging by what I've just read in an article, ...      0\n",
       "64488   Todd and Copper\\nIn the first film they were l...      0\n",
       "16992   \"\\n\\n \\nYou have been blocked from editing for...      0\n",
       "138230  | decline=Can't find evidence of block either ...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10, random_state=rnd_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Загрузка данных проведена хорошо. Не забывай проверять загруженные файлы на пропуски.\n",
    "</div>\n",
    "\n",
    "- готово"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = data['text'].str.len().max()\n",
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Можно было даже построить гистограмму распределния длины.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на баланс классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa297fd50d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['toxic'].value_counts().plot(kind='bar', color='#009900')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Радует, что ты визуализировала баланс классов.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Процентное соотношение токсичных комментариев: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic ratio: 10.17%\n"
     ]
    }
   ],
   "source": [
    "toxic_ratio = pd.Series(data['toxic']==1).sum()/data.shape[0]\n",
    "print('toxic ratio: {:.2%}'.format(toxic_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем дисбаланс классов, токсичных комментариев намного меньше. Учтем его в дальнейшей обработке. \n",
    "\n",
    "Для дальнейшей работы необходимо лемматизировать текст:\n",
    "\n",
    "- определим слова токенов, стоп-слова\n",
    "- уберем знаки припенания\n",
    "- уберем стоп-слова\n",
    "- добавим фильтр для знаков припенания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "punctuation = string.punctuation \n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokens = [ word for sent in sent_tokenize(text) for word in word_tokenize(sent)]\n",
    "    tokens = list(filter(lambda t: t not in punctuation, tokens)) \n",
    "    tokens = list(filter(lambda t: t.lower() not in stop_words, tokens))\n",
    "    filtered_tokens = []\n",
    "    for token in tokens: # Регулярные выражений\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    filtered_tokens = list(\n",
    "        map(lambda token: wordnet_lemmatizer.lemmatize(token.lower()), filtered_tokens))\n",
    "    filtered_tokens = list(filter(lambda t: t not in punctuation, filtered_tokens))\n",
    "    return ' '.join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 13s, sys: 643 ms, total: 4min 13s\n",
      "Wall time: 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text_clean'] = data['text'].map(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Лемматизация и очистка текста сделаны отлично.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию, которая разделит датасет на : обущающий, валидацилный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_valid(dataframe, test_size, valid_size):\n",
    "    \n",
    "    data_train, data_test = train_test_split(\n",
    "        dataframe,\n",
    "        test_size=test_size,\n",
    "        shuffle = False,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    post_split_valid_size = valid_size / (1 - test_size)\n",
    "    data_train, data_valid = train_test_split(\n",
    "        data_train,\n",
    "        test_size=post_split_valid_size,\n",
    "        shuffle =False ,\n",
    "        \n",
    "    )\n",
    "    return data_train, data_test, data_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(111698, 3) (15958, 3) (31915, 3)\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, data_valid = split_train_test_valid(data, 0.1, 0.2)\n",
    "\n",
    "print(data_train.shape, data_test.shape, data_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Хорошо, что были напечатаны размеры полученных наборов.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww match background colour 'm seemingly stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man 'm really trying edit war 's guy const...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>ca n't make real suggestion improvement wonder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>congratulation well use tool well talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>vandalism matt shirvington article reverted pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry word 'nonsense offensive anyway 'm inten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>\"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...</td>\n",
       "      <td>0</td>\n",
       "      <td>fair use rationale image wonju.jpg thanks uplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>bbq \\n\\nbe a man and lets discuss it-maybe ove...</td>\n",
       "      <td>0</td>\n",
       "      <td>bbq man let discus it-maybe phone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>hey it.. talk exclusive group wp taliban good ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Before you start throwing accusations and warn...</td>\n",
       "      <td>0</td>\n",
       "      <td>start throwing accusation warning let review e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>oh girl started argument stuck nose n't belong...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic  \\\n",
       "0   Explanation\\nWhy the edits made under my usern...      0   \n",
       "1   D'aww! He matches this background colour I'm s...      0   \n",
       "2   Hey man, I'm really not trying to edit war. It...      0   \n",
       "3   \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4   You, sir, are my hero. Any chance you remember...      0   \n",
       "5   \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6        COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7   Your vandalism to the Matt Shirvington article...      0   \n",
       "8   Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9   alignment on this subject and which are contra...      0   \n",
       "10  \"\\nFair use rationale for Image:Wonju.jpg\\n\\nT...      0   \n",
       "11  bbq \\n\\nbe a man and lets discuss it-maybe ove...      0   \n",
       "12  Hey... what is it..\\n@ | talk .\\nWhat is it......      1   \n",
       "13  Before you start throwing accusations and warn...      0   \n",
       "14  Oh, and the girl above started her arguments w...      0   \n",
       "\n",
       "                                           text_clean  \n",
       "0   explanation edits made username hardcore metal...  \n",
       "1   d'aww match background colour 'm seemingly stu...  \n",
       "2   hey man 'm really trying edit war 's guy const...  \n",
       "3   ca n't make real suggestion improvement wonder...  \n",
       "4                    sir hero chance remember page 's  \n",
       "5              congratulation well use tool well talk  \n",
       "6                         cocksucker piss around work  \n",
       "7   vandalism matt shirvington article reverted pl...  \n",
       "8   sorry word 'nonsense offensive anyway 'm inten...  \n",
       "9                alignment subject contrary dulithgow  \n",
       "10  fair use rationale image wonju.jpg thanks uplo...  \n",
       "11                  bbq man let discus it-maybe phone  \n",
       "12  hey it.. talk exclusive group wp taliban good ...  \n",
       "13  start throwing accusation warning let review e...  \n",
       "14  oh girl started argument stuck nose n't belong...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы: \n",
    "\n",
    "- Наблюдается дисбаланс классов, токсичных комментариев примерно 10% от всех \n",
    "- Был использован map\n",
    "- Текст очистили и лемматизировали"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиваем датасет на обучающую, тестовую и валидационную выборки. Для тестовой выборки нам необходимо 10% от исходных данных. Разделяем данные на обычные и целевые признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение TF-IDF для обучения моделей как признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = data_train['text_clean'].values.astype('U')\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "tfidf_train = count_tf_idf.fit_transform(train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение таргета для обучения моделей\n",
    "target_train = data_train['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_target = data_valid['toxic']\n",
    "valid_corpus = data_valid['text_clean'].values.astype('U')\n",
    "tfidf_valid = count_tf_idf.transform(valid_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Радует, что векторизатор был обучен только на тренировочной части. Это поможет уменьшить переобечение модели.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Рассмотрим 3 модели классификации и выберем наиболее подходящую для нашей задачи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= ({'penalty': 'l1'}, {'max_iter': 2}) f1_logic 0.7423501720079667\n",
      "i= ({'penalty': 'l1'}, {'max_iter': 5}) f1_logic 0.7653880463871544\n",
      "i= ({'penalty': 'l1'}, {'max_iter': 100}) f1_logic 0.7647583377920456\n",
      "i= ({'penalty': 'l2'}, {'max_iter': 2}) f1_logic 0.0\n",
      "i= ({'penalty': 'l2'}, {'max_iter': 5}) f1_logic 0.58335144533797\n",
      "i= ({'penalty': 'l2'}, {'max_iter': 100}) f1_logic 0.7266475644699141\n",
      "CPU times: user 9.94 s, sys: 5.14 s, total: 15.1 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f1_logic = dict()\n",
    "for i in product([{'penalty':'l1'},{'penalty':'l2'}],\n",
    "              [{'max_iter':2},{ 'max_iter':5}, {'max_iter':100}]\n",
    "              ):\n",
    "    model_logic = LogisticRegression(random_state = rnd_state,**i[0],**i[1])\n",
    "    model_logic.fit(tfidf_train, target_train)\n",
    "    predicted_logic = model_logic.predict(tfidf_valid)\n",
    "    f1_logic = f1_score(valid_target, predicted_logic)\n",
    "    print('i=', i, 'f1_logic', f1_logic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Параметры не изменяются.\n",
    "</div>\n",
    "\n",
    "- готово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= ({'C': 0.1}, {'max_iter': 5}) f1_svc 0.7313632030505244\n",
      "i= ({'C': 0.1}, {'max_iter': 10}) f1_svc 0.7323675181090356\n",
      "i= ({'C': 0.1}, {'max_iter': 100}) f1_svc 0.7323675181090356\n",
      "i= ({'C': 1.0}, {'max_iter': 5}) f1_svc 0.7682166399429895\n",
      "i= ({'C': 1.0}, {'max_iter': 10}) f1_svc 0.7735288982015016\n",
      "i= ({'C': 1.0}, {'max_iter': 100}) f1_svc 0.7747559274755927\n",
      "i= ({'C': 2.5}, {'max_iter': 5}) f1_svc 0.7615645651009109\n",
      "i= ({'C': 2.5}, {'max_iter': 10}) f1_svc 0.7709516434348648\n",
      "i= ({'C': 2.5}, {'max_iter': 100}) f1_svc 0.7682074023537439\n",
      "CPU times: user 5.7 s, sys: 3.73 ms, total: 5.7 s\n",
      "Wall time: 5.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "f1_svc = dict()\n",
    "for i in product([{'C':0.1},{'C':1.0} ,{'C':2.5}],\n",
    "              [{'max_iter':5},{ 'max_iter':10}, {'max_iter':100}]\n",
    "              ):\n",
    "    model_svc = LinearSVC(random_state = rnd_state,**i[0],**i[1])\n",
    "    model_svc.fit(tfidf_train, target_train)\n",
    "    predicted_svc = model_svc.predict(tfidf_valid)\n",
    "    f1_svc = f1_score(valid_target, predicted_svc)\n",
    "    print('i=', i, 'f1_svc', f1_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Аналогично, подбор параметров не производится.\n",
    "</div>\n",
    "\n",
    "- готово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Модель RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.2 s, sys: 19.3 ms, total: 18.2 s\n",
      "Wall time: 18.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.761821620835152"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_clf = RidgeClassifier(alpha = 1, normalize = True)\n",
    "model_clf.fit(tfidf_train, target_train)\n",
    "predicted_clf = model_clf.predict(tfidf_valid)\n",
    "f1_clf = f1_score(valid_target, predicted_clf)\n",
    "f1_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Радует, что ты попробовала несколько моделей!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы: \n",
    "\n",
    "Исходя из анализа: можно сделать вывод, что модель \"LinearSVC\" с параметрами i= ({'C': 1.0}, {'max_iter': 100}) f1_svc 0.7747559274755927 наиболее подходящая. Далее проведем тестирование, чтобы подтвердить наше предположение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7743257084329122"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_target = data_test['toxic'] \n",
    "test_corpus = data_test['text_clean'].values.astype('U') \n",
    "\n",
    "tfidf_test = count_tf_idf.transform(test_corpus) \n",
    "\n",
    "best_model = LinearSVC(random_state = rnd_state,  max_iter= 100) \n",
    "\n",
    "best_model.fit(tfidf_train, target_train)\n",
    "predicted_test = best_model.predict(tfidf_test) \n",
    "f1 = f1_score(test_target, predicted_test) \n",
    "f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> В этой части нет вывода.\n",
    "</div>\n",
    "\n",
    "- готово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалось достичь нужной выличены f1 меры на тестовой выборке при помощи модели LinearSVC с параметром max_iter = 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Пожалуйста, не забывай про общий вывод.\n",
    "</div>\n",
    "\n",
    "- готово"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы: \n",
    "\n",
    "- переработан массив текстовых данных\n",
    "- определили слова токенов, стоп-слова\n",
    "- уберем знаки припенания\n",
    "- уберали стоп-слова\n",
    "- добавили фильтр для знаков припенания\n",
    "- изучили три модели классификации: Логистическая регрессия, LinearSVC, RidgeClassifier\n",
    "- наилучшей моделью оказалась LinearSVC, при ней F1 равна 0.77"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Чек-лист проверки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
